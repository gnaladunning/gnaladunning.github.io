<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AR Audio Level to Text Size (HIRO Marker)</title>
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  <script src="https://cdn.rawgit.com/jeromeetienne/AR.js/master/aframe/build/aframe-ar.js"></script>
  <style>
    #startButton {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: 10;
      padding: 1em 2em;
      background: #ff3c3c;
      color: #fff;
      border: none;
      border-radius: 8px;
      font-size: 1.5em;
      font-weight: bold;
      cursor: pointer;
      box-shadow: 0 4px 24px rgba(0,0,0,0.18);
    }
  </style>
</head>
<body style="margin:0; overflow:hidden;">
  <!-- Centered Start Listening Button -->
  <button id="startButton">Start Listening</button>
  <a-scene embedded arjs="sourceType: webcam;" vr-mode-ui="enabled: false">
    <a-marker preset="hiro">
      <a-entity id="spokenText"
        text="value: Say something...; color: #FF3C3C; align: center; width: 5; anchor: center;"
        position="0 2 0"
        rotation="-90 0 0"
        scale="1 1 1">
      </a-entity>
    </a-marker>
    <a-entity camera></a-entity>
  </a-scene>
  <script>
    let recognition, audioContext, analyser, micSource, dataArray;
    let lastWord = '';
    let spokenTextEntity = document.getElementById('spokenText');

    // Speech Recognition Setup
    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (window.SpeechRecognition) {
      recognition = new window.SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US';

      recognition.onresult = function(event) {
        let transcript = '';
        for (let i = event.resultIndex; i < event.results.length; ++i) {
          transcript = event.results[i][0].transcript;
        }
        let words = transcript.trim().split(/\s+/);
        lastWord = words[words.length - 1] || '';
        spokenTextEntity.setAttribute('text', 'value', lastWord ? lastWord : 'Say something...');
      };

      recognition.onerror = function(event) {
        console.error(event.error);
      };
    } else {
      alert('Sorry, Speech Recognition is not supported on this device/browser.');
    }

    // Audio Level Setup
    function startMicLevel() {
      navigator.mediaDevices.getUserMedia({ audio: true }).then(function(stream) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        micSource = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        dataArray = new Uint8Array(analyser.frequencyBinCount);
        micSource.connect(analyser);
        animateTextScale();
      }).catch(function(err) {
        alert('Microphone access denied or not available.');
      });
    }

    function animateTextScale() {
      function updateScale() {
        if (!analyser) return;
        analyser.getByteTimeDomainData(dataArray);
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          let val = (dataArray[i] - 128) / 128;
          sum += Math.abs(val);
        }
        let average = sum / dataArray.length;
        // Scale between 1 and 3 based on loudness
        let scale = 1 + average * 6;
        spokenTextEntity.setAttribute('scale', `${scale} ${scale} ${scale}`);
        requestAnimationFrame(updateScale);
      }
      updateScale();
    }

    // Start everything on button click
    document.getElementById('startButton').addEventListener('click', function() {
      if (recognition) recognition.start();
      startMicLevel();
      this.style.display = 'none';
    });
  </script>
</body>
</html>
