<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AR Word Scatter (HIRO Marker, Mobile Ready)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
  <script src="aframe.min.js"></script>
  <script src="aframe-ar.js"></script>
  <style>
    #startButton {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: 10;
      padding: 1em 2em;
      background: #ff3c3c;
      color: #fff;
      border: none;
      border-radius: 8px;
      font-size: 1.5em;
      font-weight: bold;
      cursor: pointer;
      box-shadow: 0 4px 24px rgba(0,0,0,0.18);
    }
    body { margin:0; overflow:hidden; }
    /* Optionally, hide the video element after debugging */
    #frontCameraVideo {
      position: fixed;
      bottom: 10px;
      right: 10px;
      width: 160px;
      height: 120px;
      z-index: 20;
      background: #000;
      /* display: none; */ /* Uncomment to hide after confirming it's working */
    }
  </style>
</head>
<body>
  <button id="startButton">Start Listening</button>
  <a-scene 
    embedded 
    arjs="sourceType: webcam; facingMode: environment;" 
    vr-mode-ui="enabled: false"
    renderer="logarithmicDepthBuffer: true;"
    device-orientation-permission-ui="enabled: false">
    <a-marker preset="hiro" id="hiroMarker">
      <!-- === Plane showing the front camera feed === -->
      <a-plane
        id="frontCamPlane"
        position="0 2 -2"
        rotation="-20 0 0"
        width="1.8"
        height="1"
        material="side: double; src: #frontCameraVideo;">
      </a-plane>
      <!-- Words will be added here dynamically -->
    </a-marker>
    <a-entity camera></a-entity>
  </a-scene>

  <!-- Hidden video for front camera feed (visible for debugging; set display:none when not needed) -->
  <video
    id="frontCameraVideo"
    autoplay
    playsinline
    muted
    crossorigin="anonymous"
    style="background:#000;">
  </video>

  <script>
    // Speech recognition and AR word logic (unchanged)
    let recognition;
    let marker = document.getElementById('hiroMarker');
    let addedWords = new Set();

    function getRandomPosition() {
      let x = (Math.random() - 0.5) * 4; // -2 to 2
      let y = 1.2 + Math.random() * 2;   // 1.2 to 3.2
      let z = (Math.random() - 0.5) * 2; // -1 to 1
      return `${x.toFixed(2)} ${y.toFixed(2)} ${z.toFixed(2)}`;
    }

    function addWord(word) {
      if (!word || addedWords.has(word.toLowerCase())) return;
      addedWords.add(word.toLowerCase());

      let entity = document.createElement('a-entity');
      entity.setAttribute('text', `value: ${word}; color: #FF3C3C; align: center; anchor: center; width: 2;`);
      entity.setAttribute('position', getRandomPosition());
      entity.setAttribute('rotation', '-90 0 0');
      entity.setAttribute('scale', '2 2 2');
      marker.appendChild(entity);
    }

    document.getElementById('startButton').addEventListener('click', function() {
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(function(stream) {
          window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
          if (window.SpeechRecognition) {
            recognition = new window.SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onresult = function(event) {
              let transcript = '';
              for (let i = event.resultIndex; i < event.results.length; ++i) {
                transcript += event.results[i][0].transcript;
              }
              transcript = transcript.trim();
              let words = transcript.split(/\s+/);
              words.forEach(word => addWord(word));
            };

            recognition.onerror = function(event) {
              if (event.error === "not-allowed" || event.error === "service-not-allowed") {
                alert("Microphone or speech recognition access was not allowed. Please refresh and try again.");
              }
              console.error(event.error);
            };

            recognition.start();
          } else {
            alert('Sorry, Speech Recognition is not supported on this device/browser.');
          }
        })
        .catch(function(err) {
          alert('Microphone access denied or not available. Please enable microphone access in your browser settings.');
        });

      this.style.display = 'none';
    });

    // === Front camera video stream logic ===
    // On user gesture, request the front camera and play into the video element.
    // Some browsers block video autoplay without user interaction.
    function startFrontCamera() {
      const frontVideo = document.getElementById('frontCameraVideo');
      if (frontVideo && !frontVideo.srcObject) {
        navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" }, audio: false })
          .then(function(stream) {
            frontVideo.srcObject = stream;
            frontVideo.muted = true;
            frontVideo.play();
            // Refresh the plane's material when the video is ready
            frontVideo.onloadeddata = function() {
              const plane = document.querySelector('#frontCamPlane');
              if (plane) {
                plane.setAttribute('material', 'src', '#frontCameraVideo');
              }
            };
          })
          .catch(function(err) {
            alert("Could not access front camera: " + err.message);
            console.error("Could not access front camera:", err);
          });
      }
    }

    // Ensure both AR and front camera start after user gesture
    document.getElementById('startButton').addEventListener('click', function() {
      startFrontCamera();
    });

    // Optionally, also start front camera with any touch for easier debugging
    // window.addEventListener('touchstart', startFrontCamera, {once:true});
  </script>
</body>
</html>
