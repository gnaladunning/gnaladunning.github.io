<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Realtime Compositional Geometry Analyzer - AR Web</title>
  <meta name="viewport" content="width=device-width,initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <style>
    html, body {
      margin:0; padding:0; width:100vw; height:100vh; background:#181818; color:#fff;
      overflow:hidden; overscroll-behavior:none; font-family:sans-serif;
    }
    #cameraFeed {
      position:fixed; left:0; top:0; width:100vw; height:100vh; object-fit:cover; z-index:0; background:#000;
    }
    #overlayCanvas {
      position:fixed; left:0; top:0; width:100vw; height:100vh; z-index:1; pointer-events:none;
    }
    .controls {
      position: absolute; right: 1em; top: 1em; z-index: 2; background:rgba(30,30,30,0.80);
      border-radius:8px; padding:.7em 1em; font-size:1em;
    }
    .controls label { display:block; margin-bottom:.3em; }
    #instructions {
      background:rgba(0,0,0,0.8); color:#fff; max-width:408px;
      margin:.6em auto; border-radius: 8px; padding: 11px; font-size:.99em;
      z-index: 3; position:relative; text-align:center;
    }
    #loading {
      position:fixed; left:0; top:0; width:100vw; height:100vh; background:rgba(0,0,0,0.7);
      z-index: 100; color:#fff; display:flex; align-items:center; justify-content:center;
      font-size:1.3em; display:none;
    }
  </style>
</head>
<body>
  <div id="instructions">
    <b>Realtime Compositional Geometry AR Analyzer</b> (Experimental CV Version)<br>
    <ol style="padding-left:1.2em; text-align:left;">
      <li>Allow access to your camera if prompted.</li>
      <li>Point your device camera at images, artworks, or scenes.</li>
      <li>Compositional overlays <u>derived from CV analysis</u> will appear live.</li>
    </ol>
    <div style="margin-top:.7em; font-size:.92em;color:#cfa;">
      Processing is live and may take 1-2 seconds per frame. CV performed with OpenCV.js in-browser.<br>
      For best results: use Safari on iOS or Chrome/Edge on Android.
    </div>
  </div>
  <div id="loading">Loading computer vision library&hellip;</div>
  <div class="controls">
    <label><input type="checkbox" id="edgesChk" checked> Edges</label>
    <label><input type="checkbox" id="linesChk" checked> Lines</label>
    <label><input type="checkbox" id="contoursChk"> Contours</label>
    <label><input type="checkbox" id="circlesChk"> Circles</label>
    <label><input type="checkbox" id="cornersChk"> Corners</label>
  </div>
  <video id="cameraFeed" autoplay playsinline muted></video>
  <canvas id="overlayCanvas"></canvas>

  <!-- OpenCV.js: Latest CDN version -->
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
  <script>
    const video = document.getElementById('cameraFeed');
    const canvas = document.getElementById('overlayCanvas');
    const ctx = canvas.getContext('2d');
    const loadingDiv = document.getElementById('loading');

    // Overlay options
    const overlays = {
      edges: true,
      lines: true,
      contours: false,
      circles: false,
      corners: false
    };
    document.getElementById('edgesChk').onchange = function(){ overlays.edges = this.checked; };
    document.getElementById('linesChk').onchange = function(){ overlays.lines = this.checked; };
    document.getElementById('contoursChk').onchange = function(){ overlays.contours = this.checked; };
    document.getElementById('circlesChk').onchange = function(){ overlays.circles = this.checked; };
    document.getElementById('cornersChk').onchange = function(){ overlays.corners = this.checked; };

    function resize() {
      const w = window.innerWidth, h = window.innerHeight;
      video.style.width = w+"px";
      video.style.height = h+"px";
      canvas.width = w;
      canvas.height = h;
    }
    window.addEventListener('resize', resize);
    window.addEventListener('orientationchange', resize);
    window.addEventListener('DOMContentLoaded', resize);

    // Camera setup
    async function startCamera(){
      try {
        if (!navigator.mediaDevices) throw new Error("No camera support");
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" }, audio: false });
        video.srcObject = stream;
        await video.play();
        document.getElementById('instructions').style.display = "none";
      } catch(e) {
        alert("Camera error: " + (e.message||e));
      }
    }
    startCamera();

    // OpenCV setup
    let cvReady = false;
    function onOpenCvReady() {
      loadingDiv.style.display = 'none';
      cvReady = true;
      if (video.readyState >= 2) mainLoop();
      else video.onloadeddata = mainLoop;
    }

    // Utility: wait for OpenCV if slow network & race with onloadeddata
    function ensureCVLoaded() {
      if (!cvReady) loadingDiv.style.display = '';
      else loadingDiv.style.display = 'none';
    }

    // The main realtime CV loop (REVISED: use requestAnimationFrame for live fast analysis)
    function mainLoop() {
      ensureCVLoaded();
      if (!(video.videoWidth && video.videoHeight && cvReady)) {
        setTimeout(mainLoop, 100);
        return;
      }
      resize();

      // Setup OpenCV matrices
      let vw = canvas.width, vh = canvas.height;
      let src = new cv.Mat(vh, vw, cv.CV_8UC4);
      let gray = new cv.Mat();
      let edges = new cv.Mat();
      let lines = new cv.Mat();
      let hierarchy = new cv.Mat();
      let contours = new cv.MatVector();
      let circles = new cv.Mat();
      let corners = new cv.Mat();

      function processFrame() {
        // Draw the current video frame to the canvas
        ctx.clearRect(0,0,canvas.width,canvas.height);
        ctx.drawImage(video, 0, 0, vw, vh);

        let imageData = ctx.getImageData(0,0,vw,vh);
        src.data.set(imageData.data);

        // Convert to grayscale
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

        // Edges
        if (overlays.edges) {
          cv.Canny(gray, edges, 60, 140, 3, false);
          // Visualize edges in green
          let rgba = new cv.Mat();
          cv.cvtColor(edges, rgba, cv.COLOR_GRAY2RGBA);
          for (let i=0; i<rgba.data.length; i+=4) {
            if (rgba.data[i]>0) { rgba.data[i]=46; rgba.data[i+1]=255; rgba.data[i+2]=103;}
          }
          ctx.putImageData(new ImageData(new Uint8ClampedArray(rgba.data), vw, vh),0,0);
          rgba.delete();
        }

        // Lines (Hough)
        if (overlays.lines) {
          cv.Canny(gray, edges, 60, 140, 3, false);
          cv.HoughLinesP(edges, lines, 1, Math.PI/180, 72, 60, 10);

          ctx.save();
          ctx.globalAlpha = 0.7;
          ctx.strokeStyle = "#FFD600";
          ctx.lineWidth = 4;
          for (let i = 0; i < lines.rows; ++i) {
            let l = lines.data32S.subarray(i*4, i*4+4);
            ctx.beginPath();
            ctx.moveTo(l[0]*vw/edges.cols, l[1]*vh/edges.rows);
            ctx.lineTo(l[2]*vw/edges.cols, l[3]*vh/edges.rows);
            ctx.stroke();
          }
          ctx.restore();
        }

        // Contours
        if (overlays.contours) {
          cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
          ctx.save();
          ctx.globalAlpha = 0.7;
          ctx.lineWidth = 2.5;
          for (let i=0; i < contours.size(); ++i) {
            let c = contours.get(i);
            ctx.beginPath();
            for (let j=0; j < c.rows; ++j) {
              let pt = c.data32S.subarray(j*2, j*2+2);
              let x = pt[0] * vw / edges.cols;
              let y = pt[1] * vh / edges.rows;
              if (j==0) ctx.moveTo(x, y); else ctx.lineTo(x, y);
            }
            ctx.closePath();
            ctx.strokeStyle = "#51FF3D";
            ctx.stroke();
          }
          ctx.restore();
        }

        // Circles
        if (overlays.circles) {
          let blur = new cv.Mat();
          cv.medianBlur(gray, blur, 7);
          cv.HoughCircles(blur, circles, cv.HOUGH_GRADIENT, 1, 80, 130, 35, 15, Math.min(vw,vh)/2);
          ctx.save();
          ctx.globalAlpha = 1.0;
          ctx.strokeStyle = "#00D4F6";
          ctx.lineWidth = 4;
          for (let i=0; i<circles.cols; ++i) {
            let x = circles.data32F[i*3], y = circles.data32F[i*3+1], r=circles.data32F[i*3+2];
            ctx.beginPath();
            ctx.arc(x*vw/gray.cols, y*vh/gray.rows, r*vw/gray.cols, 0, 2*Math.PI);
            ctx.stroke();
          }
          ctx.restore();
          blur.delete();
        }

        // Corners
        if (overlays.corners) {
          cv.cornerHarris(gray, corners, 3, 3, 0.04);
          let maxVal = 0;
          for (let y=0; y<corners.rows; y++)
            for (let x=0; x<corners.cols; x++) {
              let v = corners.floatAt(y, x);
              if (v > maxVal) maxVal = v;
            }
          ctx.save();
          ctx.globalAlpha = 1.0;
          ctx.fillStyle = "#FC3898";
          for (let y=0; y<corners.rows; y++)
            for (let x=0; x<corners.cols; x++)
              if (corners.floatAt(y,x) > 0.1 * maxVal) {
                let cx = x * vw / corners.cols, cy = y * vh / corners.rows;
                ctx.beginPath(); ctx.arc(cx, cy, 6, 0, 2*Math.PI); ctx.fill();
              }
          ctx.restore();
        }
      }

      // Use requestAnimationFrame for fastest available updates (live camera analysis)
      function animationFrameLoop() {
        if (video.readyState >= 2 && cvReady) processFrame();
        requestAnimationFrame(animationFrameLoop);
      }
      animationFrameLoop();
    }
  </script>
</body>
</html>
