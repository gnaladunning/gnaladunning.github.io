<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Realtime Compositional Geometry Analyzer - AR Web</title>
  <meta name="viewport" content="width=device-width,initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <style>
    html, body {
      margin:0; padding:0; width:100vw; height:100vh; background:#181818; color:#fff;
      overflow:hidden; overscroll-behavior:none; font-family:sans-serif;
    }
    #cameraFeed {
      position:fixed; left:0; top:0; width:100vw; height:100vh; object-fit:cover; z-index:0; background:#000;
    }
    #overlayCanvas {
      position:fixed; left:0; top:0; width:100vw; height:100vh; z-index:1; pointer-events:none;
      /* important: overlay is visible over camera feed */
    }
    .controls {
      position: absolute; right: 1em; top: 1em; z-index: 2; background:rgba(30,30,30,0.80);
      border-radius:8px; padding:.7em 1em; font-size:1em;
    }
    .controls label { display:block; margin-bottom:.3em; }
    #instructions {
      background:rgba(0,0,0,0.8); color:#fff; max-width:408px;
      margin:.6em auto; border-radius: 8px; padding: 11px; font-size:.99em;
      z-index: 3; position:relative; text-align:center;
    }
    #loading {
      position:fixed; left:0; top:0; width:100vw; height:100vh; background:rgba(0,0,0,0.7);
      z-index: 100; color:#fff; display:flex; align-items:center; justify-content:center;
      font-size:1.3em; display:none;
    }
  </style>
</head>
<body>
  <div id="instructions">
    <b>Realtime Compositional Geometry AR Analyzer</b> (Experimental CV Version)<br>
    <ol style="padding-left:1.2em; text-align:left;">
      <li>Allow access to your camera if prompted.</li>
      <li>Point your device camera at images, artworks, or scenes.</li>
      <li>Compositional overlays <u>derived from CV analysis</u> will appear live.</li>
    </ol>
    <div style="margin-top:.7em; font-size:.92em;color:#cfa;">
      Processing is live and may take 1-2 seconds per frame. CV performed with OpenCV.js in-browser.<br>
      For best results: use Safari on iOS or Chrome/Edge on Android.
    </div>
  </div>
  <div id="loading">Loading computer vision library&hellip;</div>
  <div class="controls">
    <label><input type="checkbox" id="edgesChk" checked> Edges</label>
    <label><input type="checkbox" id="linesChk" checked> Lines</label>
    <label><input type="checkbox" id="contoursChk"> Contours</label>
    <label><input type="checkbox" id="circlesChk"> Circles</label>
    <label><input type="checkbox" id="cornersChk"> Corners</label>
  </div>
  <video id="cameraFeed" autoplay playsinline muted></video>
  <canvas id="overlayCanvas"></canvas>
  <!-- OpenCV.js -->
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
  <script>
    const video = document.getElementById('cameraFeed');
    const canvas = document.getElementById('overlayCanvas');
    const ctx = canvas.getContext('2d');
    const loadingDiv = document.getElementById('loading');

    // Overlay options
    const overlays = {
      edges: true,
      lines: true,
      contours: false,
      circles: false,
      corners: false
    };
    document.getElementById('edgesChk').onchange = function(){ overlays.edges = this.checked; };
    document.getElementById('linesChk').onchange = function(){ overlays.lines = this.checked; };
    document.getElementById('contoursChk').onchange = function(){ overlays.contours = this.checked; };
    document.getElementById('circlesChk').onchange = function(){ overlays.circles = this.checked; };
    document.getElementById('cornersChk').onchange = function(){ overlays.corners = this.checked; };

    function resize() {
      const w = window.innerWidth, h = window.innerHeight;
      video.style.width = w+"px";
      video.style.height = h+"px";
      canvas.width = w;
      canvas.height = h;
    }
    window.addEventListener('resize', resize);
    window.addEventListener('orientationchange', resize);
    window.addEventListener('DOMContentLoaded', resize);

    // Camera setup
    async function startCamera(){
      try {
        if (!navigator.mediaDevices) throw new Error("No camera support");
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" }, audio: false });
        video.srcObject = stream;
        await video.play();
        document.getElementById('instructions').style.display = "none";
      } catch(e) {
        alert("Camera error: " + (e.message||e));
      }
    }
    startCamera();

    // OpenCV setup
    let cvReady = false;
    function onOpenCvReady() {
      loadingDiv.style.display = 'none';
      cvReady = true;
      if (video.readyState >= 2) mainLoop();
      else video.onloadeddata = mainLoop;
    }

    // Utility: wait for OpenCV if slow network & race with onloadeddata
    function ensureCVLoaded() {
      if (!cvReady) loadingDiv.style.display = '';
      else loadingDiv.style.display = 'none';
    }

    // Smoothed polyline using Catmull-Rom spline algorithm (returns array of interpolated [x, y])
    function getSmoothCurve(pts, tension = 0.5, numSegments = 16) {
      if (pts.length < 3) return pts;
      let result = [];
      for (let i = 0; i < pts.length - 1; i++) {
        let p0 = pts[i === 0 ? i : i - 1];
        let p1 = pts[i];
        let p2 = pts[i + 1];
        let p3 = pts[i + 2 < pts.length ? i + 2 : pts.length - 1];

        for (let t = 0; t < numSegments; t++) {
          let s = t / numSegments;
          let s2 = s * s, s3 = s2 * s;

          // Catmull-Rom formula
          let x = 0.5 * ((2*p1[0]) +
            (-p0[0] + p2[0]) * s +
            (2*p0[0] - 5*p1[0] + 4*p2[0] - p3[0]) * s2 +
            (-p0[0] + 3*p1[0] - 3*p2[0] + p3[0]) * s3);

          let y = 0.5 * ((2*p1[1]) +
            (-p0[1] + p2[1]) * s +
            (2*p0[1] - 5*p1[1] + 4*p2[1] - p3[1]) * s2 +
            (-p0[1] + 3*p1[1] - 3*p2[1] + p3[1]) * s3);

          result.push([x, y]);
        }
      }
      result.push(pts[pts.length-1]);
      return result;
    }

    // The main realtime CV loop
    function mainLoop() {
      ensureCVLoaded();
      if (!(video.videoWidth && video.videoHeight && cvReady)) {
        setTimeout(mainLoop, 100);
        return;
      }
      resize();

      // OpenCV matrices (scope for frame reuse)
      let vw = canvas.width, vh = canvas.height;
      let src = new cv.Mat(vh, vw, cv.CV_8UC4);
      let gray = new cv.Mat();
      let edges = new cv.Mat();
      let lines = new cv.Mat();
      let hierarchy = new cv.Mat();
      let contours = new cv.MatVector();
      let circles = new cv.Mat();
      let corners = new cv.Mat();

      function processFrame() {
        // 1. Clear overlay canvas (NOT the camera video)
        ctx.clearRect(0,0,canvas.width,canvas.height);

        // 2. Draw current video frame to an offscreen canvas for OpenCV. Camera feed is always behind the overlay.
        // (the video element is not drawn onto the overlay canvas; it remains visible as #cameraFeed behind)
        let offCanvas = document.createElement('canvas');
        offCanvas.width = vw;
        offCanvas.height = vh;
        let offCtx = offCanvas.getContext('2d');
        offCtx.drawImage(video, 0, 0, vw, vh);
        let imageData = offCtx.getImageData(0,0,vw,vh);
        src.data.set(imageData.data);

        // Convert to grayscale
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

        // Edges
        if (overlays.edges) {
          cv.Canny(gray, edges, 60, 140, 3, false);
          // Visualize edges (alpha blend to overlay ONLY, not replace camera frame)
          let edgeImage = ctx.createImageData(vw, vh);
          for (let i = 0; i < edges.data.length; i++) {
            if (edges.data[i] > 0) {
              edgeImage.data[i * 4 + 0] = 46;
              edgeImage.data[i * 4 + 1] = 255;
              edgeImage.data[i * 4 + 2] = 103;
              edgeImage.data[i * 4 + 3] = 120; // semi-transparent
            } else {
              edgeImage.data[i * 4 + 3] = 0;
            }
          }
          ctx.putImageData(edgeImage, 0, 0);
        }

        // Lines (smoothed overlays)
        if (overlays.lines) {
          // Use edges as input
          cv.HoughLinesP(edges, lines, 1, Math.PI/180, 70, 60, 10);
          ctx.save();
          ctx.globalAlpha = 0.8;
          ctx.strokeStyle = "#FFD600";
          ctx.lineWidth = 4;
          ctx.lineJoin = "round";
          ctx.lineCap = "round";
          // For each line segment (either interpolate between segment ends for smoothness, or draw as is)
          for (let i = 0; i < lines.rows; ++i) {
            let l = lines.data32S.subarray(i*4, i*4+4);
            // Smooth short lines a bit further to avoid jaggedness:
            // We'll interpolate with a little rounding: If lines are short, bend them a little.
            let x1 = l[0]*vw/edges.cols, y1 = l[1]*vh/edges.rows;
            let x2 = l[2]*vw/edges.cols, y2 = l[3]*vh/edges.rows;
            if (Math.hypot(x2-x1, y2-y1) > 16) {
              ctx.beginPath();
              ctx.moveTo(x1, y1);
              // Instead of .lineTo, use quadratic control for smoothing
              let mx = (x1 + x2) / 2, my = (y1 + y2) / 2;
              let dx = y2-y1, dy = x1-x2;
              let mag = Math.min(8, Math.hypot(dx,dy)*0.16);
              // "Curve" offset, perpendicular to the line segment
              ctx.quadraticCurveTo(mx+mag*dx/18, my+mag*dy/18, x2, y2);
              ctx.stroke();
            } else {
              ctx.beginPath();
              ctx.moveTo(x1, y1);
              ctx.lineTo(x2, y2);
              ctx.stroke();
            }
          }
          ctx.restore();
        }

        // Contours: smoothed curves
        if (overlays.contours) {
          cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
          ctx.save();
          ctx.globalAlpha = 0.8;
          ctx.lineWidth = 2.5;
          ctx.strokeStyle = "#51FF3D";
          for (let i=0; i < contours.size(); ++i) {
            let c = contours.get(i);
            let pts = [];
            for (let j=0; j < c.rows; ++j) {
              let pt = c.data32S.subarray(j*2, j*2+2);
              let x = pt[0] * vw / edges.cols;
              let y = pt[1] * vh / edges.rows;
              pts.push([x, y]);
            }
            if (pts.length > 1) {
              const smooth = getSmoothCurve(pts, 0.5, 14);
              ctx.beginPath();
              for(let k=0;k<smooth.length;k++){
                if(k===0) ctx.moveTo(smooth[k][0], smooth[k][1]);
                else ctx.lineTo(smooth[k][0], smooth[k][1]);
              }
              ctx.closePath();
              ctx.stroke();
            }
          }
          ctx.restore();
        }

        // Circles
        if (overlays.circles) {
          let blur = new cv.Mat();
          cv.medianBlur(gray, blur, 7);
          cv.HoughCircles(blur, circles, cv.HOUGH_GRADIENT, 1, 80, 130, 35, 15, Math.min(vw,vh)/2);
          ctx.save();
          ctx.globalAlpha = 1.0;
          ctx.strokeStyle = "#00D4F6";
          ctx.lineWidth = 4;
          for (let i=0; i<circles.cols; ++i) {
            let x = circles.data32F[i*3], y = circles.data32F[i*3+1], r=circles.data32F[i*3+2];
            // Draw smooth ellipse rather than raw arc (if radii are elliptical)
            ctx.beginPath();
            ctx.ellipse(x*vw/gray.cols, y*vh/gray.rows, r*vw/gray.cols, r*vh/gray.rows, 0, 0, 2*Math.PI);
            ctx.stroke();
          }
          ctx.restore();
          blur.delete();
        }

        // Corners
        if (overlays.corners) {
          cv.cornerHarris(gray, corners, 3, 3, 0.04);
          let maxVal = 0;
          for (let y=0; y<corners.rows; y++)
            for (let x=0; x<corners.cols; x++) {
              let v = corners.floatAt(y, x);
              if (v > maxVal) maxVal = v;
            }
          ctx.save();
          ctx.globalAlpha = 1.0;
          ctx.fillStyle = "#FC3898";
          for (let y=0; y<corners.rows; y++)
            for (let x=0; x<corners.cols; x++)
              if (corners.floatAt(y,x) > 0.1 * maxVal) {
                let cx = x * vw / corners.cols, cy = y * vh / corners.rows;
                ctx.beginPath(); ctx.arc(cx, cy, 6, 0, 2*Math.PI); ctx.fill();
              }
          ctx.restore();
        }
      }

      // Use requestAnimationFrame for fastest available updates (live camera analysis)
      function animationFrameLoop() {
        if (video.readyState >= 2 && cvReady) processFrame();
        requestAnimationFrame(animationFrameLoop);
      }
      animationFrameLoop();
    }
  </script>
</body>
</html>
