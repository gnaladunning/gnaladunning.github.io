<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AR Speech-to-Text with Pitch Color (HIRO Marker)</title>
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  <script src="https://cdn.rawgit.com/jeromeetienne/AR.js/master/aframe/build/aframe-ar.js"></script>
  <style>
    #startButton {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: 10;
      padding: 1em 2em;
      background: #ff3c3c;
      color: #fff;
      border: none;
      border-radius: 8px;
      font-size: 1.5em;
      font-weight: bold;
      cursor: pointer;
      box-shadow: 0 4px 24px rgba(0,0,0,0.18);
    }
  </style>
</head>
<body style="margin:0; overflow:hidden;">
  <button id="startButton">Start Listening</button>
  <a-scene embedded arjs="sourceType: webcam;" vr-mode-ui="enabled: false">
    <a-marker preset="hiro">
      <a-entity id="spokenText"
        text="value: listening...; color: #FF3C3C; align: center; width: 5; anchor: center;"
        position="0 2 0"
        rotation="-90 0 0"
        scale="1 1 1">
      </a-entity>
    </a-marker>
    <a-entity camera></a-entity>
  </a-scene>
  <script>
    let recognition, audioContext, analyser, micSource, dataArray;
    let lastWord = '';
    let spokenTextEntity = document.getElementById('spokenText');

    // Pitch detection function (autocorrelation)
    function autoCorrelate(buffer, sampleRate) {
      let SIZE = buffer.length;
      let rms = 0;
      for (let i = 0; i < SIZE; i++) {
        let val = buffer[i];
        rms += val * val;
      }
      rms = Math.sqrt(rms / SIZE);
      if (rms < 0.01) return -1; // too quiet
      let r1 = 0, r2 = SIZE - 1, thres = 0.2;
      for (let i = 0; i < SIZE / 2; i++) {
        if (Math.abs(buffer[i]) < thres) { r1 = i; break; }
      }
      for (let i = 1; i < SIZE / 2; i++) {
        if (Math.abs(buffer[SIZE - i]) < thres) { r2 = SIZE - i; break; }
      }
      buffer = buffer.slice(r1, r2);
      SIZE = buffer.length;
      let c = new Array(SIZE).fill(0);
      for (let i = 0; i < SIZE; i++) {
        for (let j = 0; j < SIZE - i; j++) {
          c[i] = c[i] + buffer[j] * buffer[j + i];
        }
      }
      let d = 0; while (c[d] > c[d + 1]) d++;
      let maxval = -1, maxpos = -1;
      for (let i = d; i < SIZE; i++) {
        if (c[i] > maxval) {
          maxval = c[i];
          maxpos = i;
        }
      }
      let T0 = maxpos;
      if (T0 === 0) return -1;
      return sampleRate / T0;
    }

    function animateTextColor() {
      function updateColor() {
        if (!analyser) return;
        analyser.getFloatTimeDomainData(dataArray);
        let pitch = autoCorrelate(dataArray, audioContext.sampleRate);
        // Map pitch to hue: 80Hz (low) => 0deg (red), 400Hz (high) => 270deg (purple)
        let hue;
        if (pitch > 80 && pitch < 400) {
          hue = Math.floor(((pitch - 80) / (400 - 80)) * 270);
        } else {
          hue = 0; // fallback to red if out of voice range
        }
        let color = `hsl(${hue}, 90%, 55%)`;
        spokenTextEntity.setAttribute('text', 'color', color);
        requestAnimationFrame(updateColor);
      }
      updateColor();
    }

    document.getElementById('startButton').addEventListener('click', function() {
      // Start Speech Recognition
      window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (window.SpeechRecognition) {
        recognition = new window.SpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';

        recognition.onresult = function(event) {
          let transcript = '';
          for (let i = event.resultIndex; i < event.results.length; ++i) {
            transcript = event.results[i][0].transcript;
          }
          let words = transcript.trim().split(/\s+/);
          lastWord = words[words.length - 1] || '';
          spokenTextEntity.setAttribute('text', 'value', lastWord ? lastWord : 'Say something...');
        };

        recognition.onerror = function(event) {
          console.error(event.error);
        };

        recognition.start();
      } else {
        alert('Sorry, Speech Recognition is not supported on this device/browser.');
      }

      // Start Microphone and Pitch Detection
      navigator.mediaDevices.getUserMedia({ audio: true }).then(function(stream) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        micSource = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 2048;
        dataArray = new Float32Array(analyser.fftSize);
        micSource.connect(analyser);
        animateTextColor();
      }).catch(function(err) {
        alert('Microphone access denied or not available.');
      });

      // Hide button after starting
      this.style.display = 'none';
    });
  </script>
</body>
</html>
